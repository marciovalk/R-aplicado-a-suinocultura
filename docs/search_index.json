[
["ade.html", "Capítulo 4 Análise de experimentos 4.1 Príncipios e definições básicas 4.2 Experimentos com delineamento inteiramente casualizados com um fator 4.3 Delineamento fatorial com dois fatores 4.4 Exemplo da bateria 4.5 Criando um planejamento fatorial com dois fatores no R 4.6 ANOVA 1 Fator 4.7 Delineamento inteiramente casualizados 4.8 Delineamento em blocos ao acaso 4.9 Fatorial 4.10 Parcela subdividida", " Capítulo 4 Análise de experimentos Figura 4.1: Pig é Tech Nesse capítulo vamos assumir que o delineamento, planejamento ou design do experimento foi adequado e que o experimento foi corretamente conduzido. Pretendemos aqui realizar a análise dos dados e fazer a interpretação dos testes estatísticos usados para avaliar os fatores que controlam um parâmetro ou um grupo de parâmetros. Esses múltiplos fatores de entrada podem ter sido manipulados para permitir avaliar seus efeitos na variável de saída ou resposta. 4.1 Príncipios e definições básicas No livro de Lawson (2014) temos um dicionário de termos técnicos que permite um melhor acompanhamento da leitura. Experimento é uma ação em que o pesquisador altera pelo menos uma das variáveis em estudo e depois observa o efeito de suas ações através de medidas de uma característica do indivíduo (variável resposta). Exemplo: variável alterada - quantidade de mineral na ração; variável resposta - ganho e peso. Observe que coleta de dados observacionais não é experimentação. Unidade Experimental (ou parcela) é a unidade/indivíduo ao qual o tratamento será aplicado. Em geral, na suinocultura a unidade experimental é um suino. Subamostra, subunidade ou unidade observacional. Quando a unidade experimental é dividida, após a ação ter sido tomada. Isso é chamado de subamostra ou subunidade. Por exemplo, se a unidade experimental fosse uma leitegada, poderia-se considerar, após o experimento realizado, medir o peso médio das leitegadas. Às vezes, só é possível medir uma característica separadamente para cada subunidade; por esse motivo, são frequentemente chamadas de unidades observacionais. Medições em subamostras ou subunidades da mesma unidade experimental, são geralmente correlacionados e as estatísticas, como a média, devem ser calculadas antes da análise dos dados, ao invés de ser tratado como resultados independentes. Quando as subunidades podem ser consideradas independentes e existe interesse em determinar a variância nas subamostras, para não gerar nenhuma confusão no teste F para fatores de tratamento, o modelo misto deve ser usado em vez de simplesmente calcular a média das subamostras. Variável Independente (Variável preditora, Tratamento ou Fator) pode ser uma das variáveis em estudo que está sendo controlada durante o experimento, como nível, quantidade, genética. Objetivo é verificar qual o efeito que uma mudança nessa variável causa na variável resposta. Variável oculta (Background Variable ou Lurking Variable). Uma Variável independente também pode ser oculta, não controlada no experimento, mas que também pode ter efeito sobre a variável resposta. Ex: Temperatura. Em um experimento bem planejado o efeito dessa variável oculta deve estar acomodado nas demais variáveis não sendo determinante para a conclusão do estudo sobre as demais variáveis. Variável dependente (ou resposta, geralmente denotada por \\(y\\)) é a característica daunidade experimental que é medida após cada realização do experimento. Em algumas situações podemos ter mais de uma variável resposta. Efeito é a mudança na resposta causada pela mudança em um fator ou em uma variável independente/preditora. Após a realização do experimento, a análise dos dados pode chegar a conclusão de que o efeito é estatisticamente significativo, no entanto é importante que o pesquisador tenha capacidade de dizer se esse efeito tem importância prática. Isso é chamado de Efeito prático. Repetições são duas ou mais realizações de um experimento com as mesmas configurações dos fatores ou variáveis independentes mas com diferentes unidades experimentais. As medidas da variável dependente podem variar entre repetições devido à mudanças nas variáveis ocultas e diferenças inerentes às unidades experimentais. Duplicates (medidas repetidas?) refere-se à medidas duplicadas da mesma unidade experimental para a mesma realização de um experimento. Por exemplo, se a variável resposta for o Peso, realiza-se a pesagem duas vezes para eleminar algum possível viés do equipamento. É necessário fazer a média das medições e não tratar como duas variáveis respostas. Delineamento de Experimentos é uma coleção de experimentos ou execuções planejada antes da execução real. Nessa etapa são definidas a organização das unidades e a forma como estas receberão os tratamentos. Fator Confundidor surgem quando uma alteração que um experimentador faz em um fator, entre as execuções, causa uma alteração em outro fator. Ou seja, esse fator tem influência sobre a variável resposta e também sobre uma variável preditora. Fator de Vício resulta de uma ação do experimentador sobre uma variável independente no momento exato em que uma variável oculta (lurking variable) também muda. Dessa forma o efeito observado na variável resposta também pode ser devido a mudança na variável oculta, causando assim um viés. Erro Experimental é a variação ``natural´´ existente entre observações de unidades experimentais que receberam o mesmo tratamento. Essa variação pode ser devida à questões inerentes ao indivíduo ou pela falta de uniformidade na condução física do experimento, muita vezes por variáveis que não podem ser contrladas. O fato de ser chamado “erro” não quer dizer que devemos abandonar tudo. É importante que o erro experimental seja reduzido ao máximo para que se tenha maior confiabilidade nos resultados ao utilizar técnicas estatísticas. Com essas definições em mente, a diferença entre os estudos observacionais e os experimentos podem ser explicados com mais clareza. Em um estudo observacional, as variáveis (independentes e dependentes) são observadas sem qualquer tentativa de alterar ou controlar o valor dos fatores independentes. Portanto, quaisquer mudanças observadas na resposta, ou variável dependente, não podem necessariamente ser atribuídas à mudanças observadas nas variáveis independentes porque variáveis de fundo ou ocultas podem ser a causa. Em um experimento, no entanto, as variáveis independentes são propositalmente variadas e as execuções são conduzidas em uma maneira de equilibrar o efeito de quaisquer variáveis de fundo que mudam. Desta forma, a mudança média na resposta pode ser atribuída às mudanças feitas nas variáveis independentes. 4.2 Experimentos com delineamento inteiramente casualizados com um fator Em um delineamento inteiramente casualizados com um fator, N unidades experimentais (suínos) são aleatóriamente divididas em K grupos. Cada grupo fica então sujeito a um dos níveis ou valores únicos do fator de tratamento. Se cada um dos K grupos possui r unidades experimentais, então harerá r réplicas de cada execução com o mesmo nível do fator de tratamento. Se N não for múltiplo de K, então será um número desigual de repetições de cada nível de fator. Todos as demais variáveis independentes devem ser mantidas constantes para que não influenciem os efeitos desse fator. Este delineamento considera deve ser usado um fator em estudo e unidades experimentais homogêneas. 4.2.1 Granulometria ideal do grão de milho em ração para suínos Em um estudo (hipotético) para determinar a granulometria ideal do grão de milho em ração para suínos, um lote homogêneo de N=12 leitões foi dividido em \\(K=3\\) grupos (avisa o pesquisador que o tamanho da amostra é muito pequeno). Cada grupo recebeu ração composta com milho de diferentes granulometria. Os diferentes tipos de granulometria foram obtidos triturando-se 1 Kg de milho em um triturador durante 5, 10 e 15 segundos. O peso dos leitões foi aferido antes do experimento e após 3 semanas. O ganho de peso é a variável resposta, o fator de tratamento é o tempo de trituração de 1 kg de milho e a unidade experimental é cada um dos 12 leitões envolvidos no experimento. Embora outros fatores possam afetar o desempenho dos animais, como os outros componentes da ração, eles são mantidos constantes para todos os animais ao longo do experimento. 4.2.2 Replicação e randomização A replicação e a randomização foram popularizadas por Fisher. Estes são os primeiras técnicas que se enquadram na categoria de controle de erro. A técnica de replicação exige que r suínos sejam testados para cada tipo de granulagem, em vez de um único animal. Por haver replicação das unidades experimentais em cada nível do fator de tratamento, a variância do erro experimental pode ser calculado a partir dos dados, e esta variação será comparada aos efeitos do tratamento. Se a variabilidade entre os tratamentos não é maior do que a variância do erro experimental, as diferenças entre tratamentos são provavelmente devidas às diferenças das unidades experimentais atribuídas a cada tratamento. Sem replicação, é impossível dizer se a diferença entre tratamentos são reais ou apenas uma manifestação aleatória atribuídas às unidades experimentais. A divisão aleatória de unidades experimentais em grupos é chamada de aleatorização, e é o procedimento pelo qual a validade do experimento é garantida contra vieses causados por outras variáveis ocultas. Na granulagem do milho, a randomização do experimento evita variáveis ocultas, como a variabilidade na capacidade de metabolização dos suínos e sexo, por exemplo. Quando as unidades experimentais são randomizadas para os níveis do fator de tratamento, um teste de hipótese para testar a hipótese de que o efeito do tratamento é zero, pode ser realizado. Um teste para testar a significância dos parâmetros de um modelo linear, normalmente usado na análise de dados experimentais, é uma boa abordagem. 4.2.3 Exemplo de dados de delineamento inteiramente casualizados com um fator Para dar sequência ao exemplo de granulometria ideal do grão de milho em ração para suínos vamos usar o R para construir um conjunto de dados aleatorizados com as caraterísticas descritas no exemplo. Nesse caso temos o fator tempo de moagem com 3 tempos de duração (níveis), (5, 10 e 15 segundos) e a ração é oferecida para 3 grupos de 4 suínos. Podemos exemplificar esse experimento usando o seguinte código do R. set.seed(7832) temp=factor(rep(c(5,10,15),each=4)) # níveis do fator tempo fa=sample(temp, 12 ) # aleatorização dos níveis do fator tempo ind = 1:12 # Indivíduos de 1:12 (N=12) gp = c(rnorm(4,40,1),rnorm(4,41,1),rnorm(4,45,1)) # ganho de peso dados.g=data.frame(individuo=ind,fator=fa,Ganho.de.Peso=gp) print(dados.g,row.names = FALSE) ## individuo fator Ganho.de.Peso ## 1 15 38.91814 ## 2 15 39.54814 ## 3 10 39.93170 ## 4 10 40.02593 ## 5 5 40.46609 ## 6 5 40.42695 ## 7 10 40.86742 ## 8 15 43.21676 ## 9 5 46.66864 ## 10 10 45.61803 ## 11 5 46.45409 ## 12 15 46.32692 4.2.4 Modelo linear para delineamento inteiramente casualizados com um fator O modelo matemático para os dados de um delineamento inteiramente casualizados com um fator, ou delineamento completamente aleatório, com um número desigual de repetições para cada nível de fator pode ser escrito como: \\[\\begin{equation} Y_{ij}=\\mu_i+\\varepsilon_{ij} \\tag{4.1} \\end{equation}\\] em que \\(Y_{ij}\\) é a resposta para a \\(j\\)-ésima unidade experimental sujeita à \\(i\\)-ésima nível do fator de tratamento, \\(i = 1,\\dots,K\\), \\(j = 1,\\dots,r_i\\), e \\(r_i\\) é o número de unidades experimentais ou replicações no nível \\(i\\) do fator de tratamento. Ou seja, é possível que se tenha uma média diferente para cada nível \\(i\\) do tratamento. A distribuição dos erros experimentais, \\(ij\\), são mutuamente independentes devido à randomização e assumidas tendo distribuição normal. Este modelo é representado graficamente na Figura 4.2. Figura 4.2: Distribuição dos tratamentos com diferentes médias e mesma variância Uma maneira alternativa de escrever esse modelo para é \\[\\begin{equation} Y_{ij}=\\mu+\\tau_i+\\varepsilon_{ij}. \\tag{4.2} \\end{equation}\\] Isso é chamado de modelo de efeitos e \\(\\tau_i\\)’s os são chamados de efeitos. O parâmetro \\(\\tau_i\\) representa a diferença entre a média de longo prazo de todos os experimentos possíveis no \\(i\\)-ésimo nível do fator de tratamento e a média geral. Com a suposição de normalidade, \\(Y_{ij}\\sim N (\\mu+\\tau_i; \\sigma^2)\\) ou \\(\\varepsilon_{ij} \\sim N(0; \\sigma^2)\\). A média no \\(i\\)-ésimo nível do fator de tratamento é representado por \\[\\begin{equation} \\overline{y}_{i.}=\\frac{1}{r_{i}} \\sum_{j=1}^{r_{i}} y_{i j} \\tag{4.3} \\end{equation}\\] em que o \\(r_i\\) é o número de animais no i-ésimo grupo, ou seja, \\(n=\\sum r_i\\), e a grande média (média de todas as observações) é dada por \\[\\begin{equation} \\overline{y}_{..}=\\frac{1}{t} \\sum_{i=1}^{t} \\overline{y}_{i.}=\\frac{1}{n} \\sum_{i=1}^{t} \\sum_{j=1}^{r_{i}} y_{i j} \\tag{4.4} \\end{equation}\\] 4.2.4.1 Estimação Usando o método de máxima verossimilhança, que é equivalente ao método dos mínimos quadrados ordinários (MQO) com essas suposições, as estimativas das médias das células são obtidas minimizando a soma dos quadrados dos erros (SQE) \\[\\begin{equation} SQE=\\sum_{i=1}^{t} \\sum_{j=1}^{r_{i}}\\left(y_{i j}-\\mu_{i}\\right)^{2}. \\tag{4.5} \\end{equation}\\] Isso é feito tomando derivados parciais de SQE em relação a cada média da célula, igualando a zero e resolvendo cada equação teremos \\[\\frac{\\partial SQE}{\\partial \\mu_{i}}=-2 \\sum_{i=1}^{t} \\sum_{j=1}^{r_{i}}\\left(y_{i j}-\\mu_{i}\\right)=0\\] Como resultados dessa operação obtemos, para a equação (4.1), o estimador \\[\\hat{\\mu}_{i}=\\overline{y}_{i \\cdot}\\] e para a equação (4.2) \\[\\widehat{\\mu + \\tau_{i}}=\\overline{y}_{i \\cdot}\\] 4.2.4.2 Representção matricial No exemplo da granulometria, \\(i=1,2,3\\) e a equação (4.2) pode ser escrita como \\[ \\begin{align} Y_{1j}&amp;=\\mu+\\tau_1+\\varepsilon_{1j}\\\\ Y_{2j}&amp;=\\mu+\\tau_2+\\varepsilon_{2j}\\\\ Y_{3j}&amp;=\\mu+\\tau_3+\\varepsilon_{3j}\\\\ \\end{align} \\] em que \\(j = 1,\\dots,4,\\) nesse caso. Podemos escrever esse mesmo modelo de forma concisa usando a notação matricial como: \\[\\begin{equation} {\\bf y}={\\bf X }\\boldsymbol{\\beta}+\\boldsymbol{\\varepsilon}, \\tag{4.6} \\end{equation}\\] em que \\[{\\bf y}=\\left(\\begin{array}{l} y_{11} \\\\ y_{12} \\\\ y_{13} \\\\ y_{14} \\\\ y_{21} \\\\ y_{22} \\\\ y_{23} \\\\ y_{24} \\\\ y_{31} \\\\ y_{32} \\\\ y_{33} \\\\ y_{34} \\end{array}\\right),\\quad {\\bf X}=\\left(\\begin{array}{cccc} 1 &amp; 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 0 &amp; 1 &amp; 0 \\\\ 1 &amp; 0 &amp; 1 &amp; 0 \\\\ 1 &amp; 0 &amp; 1 &amp; 0 \\\\ 1 &amp; 0 &amp; 1 &amp; 0 \\\\ 1 &amp; 0 &amp; 0 &amp; 1 \\\\ 1 &amp; 0 &amp; 0 &amp; 1 \\\\ 1 &amp; 0 &amp; 0 &amp; 1 \\\\ 1 &amp; 0 &amp; 0 &amp; 1 \\end{array}\\right), \\quad\\boldsymbol{\\beta}=\\left(\\begin{array}{l} \\mu \\\\ \\tau_{1} \\\\ \\tau_{2} \\\\ \\tau_{3} \\end{array}\\right), \\quad\\boldsymbol{\\varepsilon}=\\left(\\begin{array}{c} \\epsilon_{11} \\\\ \\epsilon_{12} \\\\ \\epsilon_{13} \\\\ \\epsilon_{14} \\\\ \\epsilon_{21} \\\\ \\epsilon_{22} \\\\ \\epsilon_{23} \\\\ \\epsilon_{24} \\\\ \\epsilon_{31} \\\\ \\epsilon_{32} \\\\ \\epsilon_{33} \\\\ \\epsilon_{34} \\end{array}\\right) \\] em que \\(\\boldsymbol{\\varepsilon} \\sim MVN({\\bf 0}, \\sigma^2{\\bf I}).\\) O problema de minimizar a equação (4.5) é equivalente à resolver a equação \\({\\bf X&#39;X}\\boldsymbol{\\beta}={\\bf X&#39;y}\\) no contexto matricial. Nesse caso é necessário que \\({\\bf X&#39;X}\\) seja invertível e para que isso aconteça é necessário que as colunas de \\({\\bf X }\\) sejam linearmente independentes. Ao usarmos \\({\\bf X }\\) com 4 colunas como definida acima, termos que a coluna 1 é combinação linear das outras 3, e isso implicará na não invertibilidade de \\({\\bf X&#39;X}\\). Por isso é necessário reescrever \\({\\bf X }\\) com apenas 3 colunas, removendo aquela correspondente ao primeiro nível do fator (tempo igual à 5 segundos). Dessa forma, \\[{\\bf X}=\\left(\\begin{array}{lll} 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 \\\\ 1 &amp; 0 &amp; 1 \\\\ 1 &amp; 0 &amp; 1 \\\\ 1 &amp; 0 &amp; 1 \\\\ 1 &amp; 0 &amp; 1 \\end{array}\\right) \\] Esta codificação de tratamento torna padrão o primeiro nível do fator, e todos os outros níveis do fator são comparados a ele. Para o exemplo com \\(K = 3\\) níveis de fator, a solução para via método de mínimos quadrados (MQO) de \\({\\bf X&#39;X\\beta=X&#39;y}\\) é \\[\\begin{equation} \\hat{\\boldsymbol{\\beta}}=\\left(\\boldsymbol{X}^{\\prime} \\boldsymbol{X}\\right)^{-1} \\boldsymbol{X}^{\\prime} \\boldsymbol{y}, \\tag{4.7} \\end{equation}\\] o que resulta em \\[ \\hat{\\boldsymbol{\\beta}}=\\left(\\begin{array}{c} \\hat{\\mu}+\\hat{\\tau}_{1} \\\\ \\hat{\\tau}_{2}-\\hat{\\tau}_{1} \\\\ \\hat{\\tau}_{3}-\\hat{\\tau}_{1} \\end{array}\\right), \\] ou seja, nessa fomulação é retornado a diferença do tratamento 2 para o tratamento 1 (\\(\\hat{\\tau}_{2}-\\hat{\\tau}_{1}\\)) e a diferença do tratamento 3 para o tratamento 1 (\\(\\hat{\\tau}_{3}-\\hat{\\tau}_{1}\\)). Em termos de testes de hipóteses, para que exista diferença entre os tratamentos, basta que \\(\\hat{\\tau}_{2}-\\hat{\\tau}_{1}\\) ou \\(\\hat{\\tau}_{3}-\\hat{\\tau}_{1}\\) seja significativamente diferente de zero. 4.2.4.3 Mínimos quadrados com o R Vamos usar o R para resolver essas diferentes equações através de MQO e entender os resultados. y=dados.g$Ganho.de.Peso # variável resposta/dependente X=model.matrix(~dados.g$fator) # criando a matrix X do modelo matricial colnames(X)=c(&quot;Intercepto&quot;,&quot;Fator.10&quot;,&quot;Fator.15&quot;) X ## Intercepto Fator.10 Fator.15 ## 1 1 0 1 ## 2 1 0 1 ## 3 1 1 0 ## 4 1 1 0 ## 5 1 0 0 ## 6 1 0 0 ## 7 1 1 0 ## 8 1 0 1 ## 9 1 0 0 ## 10 1 1 0 ## 11 1 0 0 ## 12 1 0 1 ## attr(,&quot;assign&quot;) ## [1] 0 1 1 ## attr(,&quot;contrasts&quot;) ## attr(,&quot;contrasts&quot;)$`dados.g$fator` ## [1] &quot;contr.treatment&quot; beta= solve(t(X)%*%X)%*%t(X)%*%y # MQO matricial print(beta) ## [,1] ## Intercepto 43.50394 ## Fator.10 -1.89317 ## Fator.15 -1.50145 Assim temos que a diferença nas médias de ganho de peso para os animais que foram tratados com granulagem “10” para os que foram tratados com granulagem “5” é \\(\\hat{\\tau}_{2}-\\hat{\\tau}_{1} = -1.8931704\\) e a diferença nas médias de ganho de peso para os animais que foram tratados com granulagem “15” para os que foram tratados com granulagem “5” é \\(\\hat{\\tau}_{3}-\\hat{\\tau}_{1}=-1.5014501\\). 4.2.5 Fatores e delineamentos fatoriais Muitos experimentos envolvem o estudo de efeitos de dois ou mais fatores. Em geral, delineamentos fatoriais são mais eficientes para este tipo de experimento. Por delineamento fatorial, queremos dizer que em cada replicação completa do experimento todas as possíveis combinações são investigadas. Por exemplo, se existem \\(a\\) níveis do fator \\(A\\) e \\(b\\) níveis do fator \\(B\\), cada replicação contém todas as combinações de tratamentos \\(ab\\). Quando os fatores são organizados em um delineamento fatorial, eles costumam ser cruzados. 4.2.6 Fatores e delineamentos fatoriais De maneira geral, quando se fala de fatoriais não se está falando em delineamentos de experimentos, e sim em delineamentos de tratamentos. No entanto, como será visto no curso, existem algumas modificações nos delineamentos básicos que só podem ser aplicadas aos ensaios fatoriais. 4.2.7 Fatores e delineamentos fatoriais Chama-se de fator àquilo que se quer testar e de níveis às suas diferentes manifestações. Por exemplo, em estudos de adubação de plantas, três elementos - nitrogênio (N), fósforo (P) e potássio (K) - são considerados os macronutrientes. Assim, cada elemento é considerado um fator, e suas diferentes doses de aplicação níveis. Se apenas um elemento for testado num ensaio, cada nível será chamado de tratamento. Por sua vez, se dois ou três elementos forem testados, cada combinação entre seus níveis é que será declarada como um tratamento. Os fatores podem ser quantitativos: doses, espaçamento entre plantas, etc; ou qualitativos: cultivares, etc. 4.2.8 Efeitos principais O efeito de um fator é definido como a mudança na resposta produzida pela mudança no nível do fator. Este é frequentemente chamado de efeito principal porque se refere aos principais fatores no experimento. 4.2.8.1 Experimento fatorial com dois fatores com dois níveis set.seed(7638) f &lt;- factor( rep( c(35, 40, 45 ), each = 4)) fac &lt;- sample( f, 12 ) eu &lt;- 1:12 plan &lt;- data.frame( loaf=eu, time=fac ) 4.2.9 Efeitos principais \\[ A = \\bar{y}_{A^{+}} - \\bar{y}_{A^{-}} = \\frac{40 + 52}{2} - \\frac{20 + 30}{2} = 21 \\] Aumento na média da resposta de 21 unidades. Similarmente, temos que o efeito principal de \\(B\\) é \\[ B = \\bar{y}_{B^{+}} - \\bar{y}_{B^{-}} = \\frac{30 + 52}{2} - \\frac{20 + 40}{2} = 11 \\] 4.2.10 Efeito de interação Em alguns experimentos, nós poderemos encontrar que a diferença na resposta entre os níveis de um fator não é o mesmo em todos os níveis dos outros fatores. Quando isto ocorre, existe uma interação entre os fatores. 4.2.10.1 Outro experimento fatorial com dois fatores com dois níveis 4.2.11 Efeito de interação No nível \\(B^{-}\\), o efeito de \\(A\\) é \\[ A = 50 - 20 = 30 \\] No nível \\(B^{+}\\), o efeito de \\(A\\) é \\[ A = 12 - 40 = - 28 \\] A magnitude do efeito de interação é a diferença média desses dois efeitos \\(A\\), ou \\[ AB = \\frac{-28 - 30}{2} = -29 \\] 4.2.12 Efeito de interação 4.2.13 Representação por modelo de regressão \\[ y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_{12}x_1x_2 + \\epsilon \\] \\(y\\) é a resposta \\(\\beta\\)’s são parâmetros \\(x_1\\) representa o fator \\(A\\) (escala contínua de -1 a 1) \\(x_2\\) representa o fator \\(B\\) (escala contínua de -1 a 1) \\(\\epsilon\\) é o erro aleatório 4.2.14 Representação por modelo de regressão (ausência de interação) \\[ \\hat{y} = 35.5 + 10.5x_1 + 5.5x_2 + 0.5x_1x_2 \\approx 35.5 + 10.5x_1 + 5.5x_2 \\] 4.2.15 Representação por modelo de regressão (presença de interação) \\[ \\hat{y} = 35.5 + 10.5x_1 + 5.5x_2 + 8x_1x_2 \\] “Interação é uma forma de curvatura” 4.2.16 Efeitos principais vs efeito de interação Geralmente quando um efeito de interação é grande, os efeitos principais correspondentes têm pouco significado prático. \\(A = \\bar{y}_{A^{+}} - \\bar{y}_{A^{-}} = \\frac{50 + 12}{2} - \\frac{20 + 40}{2} = 1\\), que é bem pequeno, e nós ficamos tentados a concluir que não existe efeito devido ao \\(A\\). No entanto, quando examinamos os efeitos de \\(A\\) em diferentes níveis do fator \\(B\\), vemos que isto não se confirma. O fator \\(A\\) tem um efeito, mas depende do nível do fator \\(B\\). 4.2.17 Efeitos principais vs efeito de interação Ou seja, o conhecimento da interação \\(AB\\) é mais útil que o conhecimento do efeito principal. Uma interação significativa geralmente irá mascarar a significância dos efeitos principais. Na presença de interação significativa, o pesquisador deve usualmente examinar os níveis de um fator, fator \\(A\\), com os níveis do outro fator fixados para obter conclusões sobre efeito principal de \\(A\\). 4.3 Delineamento fatorial com dois fatores 4.3.1 Delineamento fatorial com dois fatores Os tipos de delineamentos fatoriais mais simples envolvem apenas dois fatores ou conjuntos de tratamentos. Existem \\(a\\) níveis do fator \\(A\\) e \\(b\\) níveis do fator \\(B\\), e estes são organizados em um delineamento fatorial. 4.4 Exemplo da bateria Um engenheiro está desenhando uma bateria para ser usada em um dispositivo que estará sujeita a variações de temperatura. Três tipos de materiais (MT) são possíveis para a fabricação da bateria. Três temperaturas, consistentes com as temperaturas do ambiente de uso. Quatro baterias foram testadas em cada combinação de material e temperatura. Delineamento fatorial \\(3^2\\). 4.4.1 Exemplo da bateria Quais os efeitos do tipo e temperatura do material na vida? Existe uma escolha de material que daria vida longa, independentemente da temperatura (um produto robusto)? ## Exemplo da bateria \\(a\\) níveis do fator \\(A\\); \\(b\\) níveis do fator \\(B\\); \\(n\\) replicações. Este é um delineamento completamente aleatorizado. 4.4.2 Exemplo da bateria O modelo de efeitos: \\[ y_{ijk} = \\mu + \\tau_i + \\beta_j + (\\tau\\beta)_{ij} + \\epsilon_{ijk}, i = 1, \\ldots, a, j = 1,\\ldots, b, k = 1, \\ldots, n. \\] 4.4.3 Exemplo da bateria Em um experimento fatorial com dois fatores, os fatores \\(A\\) e \\(B\\) são de igual interesse. Especificamente, estamos interessados em testar hipóteses sobre a igualdade dos efeitos de tratamento das linhas \\[ H_0: \\tau_1 = \\tau_2 = \\ldots = \\tau_a = 0\\quad vs.\\quad H_1:\\mbox{pelo menos um } \\tau_i \\neq 0 \\] e a igualdade dos efeitos de tratamento das colunas \\[ H_0: \\beta_1 = \\beta_2 = \\ldots = \\beta_b = 0\\quad vs.\\quad H_1:\\mbox{pelo menos um } \\beta_j \\neq 0 \\] Também estamos interessados em determinar em que linha e coluna os tratamentos interagem \\[ H_0: (\\tau\\beta)_{ij} = 0\\quad vs.\\quad H_1:\\mbox{pelo menos um } (\\tau\\beta)_{ij} \\neq 0 \\] - Pergunta: O que estas hipóteses representam na prática? - Cenas dos próximos capítulos: Análise de variância de dois fatores 4.5 Criando um planejamento fatorial com dois fatores no R 4.5.1 Exemplo da bateria D &lt;- expand.grid(MT = 1:3, T = c(15, 70, 125)) D ## MT T ## 1 1 15 ## 2 2 15 ## 3 3 15 ## 4 1 70 ## 5 2 70 ## 6 3 70 ## 7 1 125 ## 8 2 125 ## 9 3 125 D &lt;- rbind(D, D, D, D) set.seed(2591) D &lt;- D[order(sample(1:36)), ] BatteryDes &lt;- D[ c( &quot;MT&quot;, &quot;T&quot; )] BatteryDes write.csv(BatteryDes, file = &quot;BatteryDes.csv&quot;, row.names = FALSE) 4.5.2 As vantagens dos delineamentos fatoriais 4.5.3 Para casa Discuta as vantagens dos delineamentos fatoriais em comparação com o delineamento um fator por vez. Veja Czitrom, V. “One-Factor-at-a-Time Versus Designed Experiments”. The American Statistician, 53:126-131, 1999. 4.6 ANOVA 1 Fator 4.7 Delineamento inteiramente casualizados 4.8 Delineamento em blocos ao acaso 4.9 Fatorial 4.10 Parcela subdividida Referências "]
]
